{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Setup","metadata":{}},{"cell_type":"code","source":"\n!pip install -q accelerate transformers peft deepspeed trl bitsandbytes datasets flash-attn --upgrade\n!pip install -q unsloth\n!pip install -q wandb","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-04T19:47:39.026636Z","iopub.execute_input":"2025-11-04T19:47:39.027288Z","iopub.status.idle":"2025-11-04T19:47:42.371850Z","shell.execute_reply.started":"2025-11-04T19:47:39.027245Z","shell.execute_reply":"2025-11-04T19:47:42.370865Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"with open('deepspeed_zero3_config.yaml', 'w') as f:\n    f.write(deepspeed_config)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with open('train.py', 'w') as f:\n    f.write(train_script)  \n\nwith open('utils.py', 'w') as f:\n    f.write(utils_script)  \n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!accelerate launch --config_file \"deepspeed_zero3_config.yaml\" train.py \\\n  --seed 42 \\\n  --model_name_or_path \"linyilama/linyilama-1.18-Chat-v1.0\" \\\n  --dataset_name \"owl-health/medical-dialogue-to-soap-summary\" \\\n  --chat_template_format \"chatml\" \\\n  --add_special_tokens False \\\n  --append_concat_token False \\\n  --splits \"train,test\" \\\n  --max_seq_length 2048 \\\n  --num_train_epochs 1 \\\n  --logging_steps 5 \\\n  --log_level \"info\" \\\n  --logging_strategy \"steps\" \\\n  --evaluation_strategy \"epoch\" \\\n  --save_strategy \"epoch\" \\\n  --bf16 True \\\n  --packing True \\\n  --learning_rate 1e-4 \\\n  --lr_scheduler_type \"cosine\" \\\n  --weight_decay 1e-4 \\\n  --warmup_ratio 0.0 \\\n  --max_grad_norm 1.0 \\\n  --output_dir \"llama-medical-finetuned\" \\\n  --per_device_train_batch_size 2 \\\n  --per_device_eval_batch_size 2 \\\n  --gradient_accumulation_steps 2 \\\n  --gradient_checkpointing True \\\n  --use_reentrant True \\\n  --dataset_text_field \"text\" \\\n  --use_flash_attn True \\\n  --use_peft_lora True \\\n  --lora_r 64 \\\n  --lora_alpha 16 \\\n  --lora_dropout 0.1 \\\n  --lora_target_modules \"q_proj,k_proj,v_proj,o_proj,down_proj,up_proj,gate_proj\" \\\n  --use_4bit_quantization True \\\n  --use_nested_quant True","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Training progress","metadata":{}},{"cell_type":"code","source":"import time\nwhile True:\n    try:\n        with open('llama-medical-finetuned/trainer_state.json', 'r') as f:\n            import json\n            state = json.load(f)\n            print(f\"Epoch: {state['epoch']:.2f}, Step: {state['step']}/{state['max_steps']}\")\n        time.sleep(60)\n    except:\n        print(\"Training in progress...\")\n        time.sleep(60)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}